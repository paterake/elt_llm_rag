# Shared RAG Configuration

# ChromaDB settings
chroma:
  persist_dir: "../chroma_db"
  tenant: "rag_tenants"
  database: "knowledge_base"

# Ollama settings
ollama:
  base_url: "http://localhost:11434"
  embedding_model: "nomic-embed-text"  # keep this, it's good
  llm_model: "qwen2.5:14b"     # ~9GB â€” excellent instruction following
  embed_batch_size: 1
  context_window: 8192          # enough for 10-15 retrieved chunks

# Chunking settings
chunking:
  strategy: "sentence"  # or "semantic"
  chunk_size: 512
  chunk_overlap: 64
  sentence_split_threshold: 0.5

# Query settings
query:
  similarity_top_k: 10
  use_hybrid_search: true  # Combine BM25 keyword + vector search (fixes structured/list content)
  system_prompt: |
    You are a helpful assistant that answers questions based on the provided documents.
    Always ground your answers in the retrieved content.
    When the documents clearly list items (such as chapters, steps, or roles), enumerate them explicitly.
    When the documents only partially describe something, say that the list may be incomplete and explain what is stated.
    If the information is not available in the documents, say so clearly.
